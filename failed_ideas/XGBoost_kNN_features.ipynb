{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapkprecision(truthvalues, predictions):\n",
    "    '''\n",
    "    This is a faster implementation of MAP@k valid for numpy arrays.\n",
    "    It is only valid when there is one single truth value. \n",
    "\n",
    "    m ~ number of observations\n",
    "    k ~ MAP at k -- in this case k should equal 3\n",
    "\n",
    "    truthvalues.shape = (m,) \n",
    "    predictions.shape = (m, k)\n",
    "    '''\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return np.mean(np.sum(z, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "initial_date = np.datetime64('2014-01-01T01:01', dtype='datetime64[m]')\n",
    "d_times = pd.DatetimeIndex(initial_date + np.timedelta64(int(mn), 'm')\n",
    "                           for mn in train_set.time.values)\n",
    "train_set['hour'] = (d_times.hour+ d_times.minute/60)\n",
    "train_set['weekday'] = d_times.weekday \n",
    "train_set['month'] = d_times.month \n",
    "train_set['year'] = (d_times.year - 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_map3_xgboost(xlower, xupper, ylower, yupper, cut_threshold=10, \n",
    "                            n_estimators=100, gamma=0.01, subsample=0.95, learning_rate=0.1,\n",
    "                            colsample_bytree = 1., colsample_bylevel=1., reg_alpha=1.,\n",
    "                            reg_lambda=0., min_child_weight=0.3, max_depth=4,\n",
    "                            margin=0.\n",
    "                           ):\n",
    "    #print(locals())\n",
    "    \n",
    "    epsilon = 1.0e-5\n",
    "    \n",
    "    if xupper == 10.:\n",
    "        xupper += epsilon\n",
    "    if yupper == 10.:\n",
    "        yupper += epsilon\n",
    "    \n",
    "    train_set_bin_2 = train_set[(train_set.x >= xlower - margin) & (train_set.x < xupper + margin) \n",
    "                              & (train_set.y >= ylower - margin) & (train_set.y < yupper + margin)].copy()\n",
    "    train_set_bin_2.sort_values('time', inplace=True)\n",
    "    Nrows = train_set_bin_2.shape[0]\n",
    "    \n",
    "    eighty_percent_mark = int(0.8*Nrows)\n",
    "    \n",
    "    train_set_bin = train_set_bin_2[:eighty_percent_mark]\n",
    "    \n",
    "    #take the final 20% and shuffle it\n",
    "    validation_set = train_set_bin_2[eighty_percent_mark:]\n",
    "    \n",
    "    N_iter = 5 # this randomly reshuffles the data between the training and testing sets and averages\n",
    "    # reduces overfitting by bayesian optimizer due to choice of train, validation split\n",
    "    \n",
    "    map3_values = []\n",
    "    \n",
    "    for i in range(N_iter):\n",
    "        new_train_set_bin = train_set_bin.copy()\n",
    "        new_validation_set_bin = validation_set.sample(frac=1.) \n",
    "    \n",
    "        # take half the shuffled data, append to train set, and the other half is for \n",
    "        # the validation set.\n",
    "        half_mark = int(new_validation_set_bin.shape[0] * 0.5)\n",
    "        new_train_set_bin.append(new_validation_set_bin[:half_mark])\n",
    "        new_validation_set_bin = new_validation_set_bin[half_mark:]\n",
    "        new_validation_set_bin = new_validation_set_bin[(new_validation_set_bin.x >= xlower) \n",
    "                                                        & (new_validation_set_bin.x < xupper)\n",
    "                                                        & (new_validation_set_bin.y >= ylower)\n",
    "                                                        & (new_validation_set_bin.y < yupper)\n",
    "                                                       ]\n",
    "    \n",
    "        place_counts = new_train_set_bin.place_id.value_counts()\n",
    "        mask = place_counts[new_train_set_bin.place_id.values] >= cut_threshold\n",
    "        new_train_set_bin = new_train_set_bin.loc[mask.values]\n",
    "\n",
    "        X_train = new_train_set_bin['x y accuracy hour weekday month year'.split()].as_matrix()\n",
    "        Y_train = new_train_set_bin['place_id'].values\n",
    "\n",
    "        X_vali = new_validation_set_bin['x y accuracy hour weekday month year'.split()].as_matrix()\n",
    "        Y_vali = new_validation_set_bin['place_id'].values\n",
    "\n",
    "        classifier = xgboost.XGBClassifier(n_estimators=int(round(n_estimators)), objective='multi:softprob',\n",
    "                                           learning_rate=float(learning_rate),\n",
    "                                           gamma=gamma, subsample=subsample,\n",
    "                                           colsample_bytree = colsample_bytree, \n",
    "                                           colsample_bylevel = colsample_bylevel, \n",
    "                                           reg_alpha=reg_alpha,\n",
    "                                           reg_lambda=reg_lambda,\n",
    "                                           min_child_weight=min_child_weight,\n",
    "                                           max_depth=int(round(max_depth))\n",
    "                                          )\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        predict_y_vali = classifier.predict_proba(X_vali)\n",
    "        predicted_vali_idx = np.argsort(\n",
    "                predict_y_vali, axis=1)[:, -3:][:, ::-1]\n",
    "        map3 = mapkprecision(Y_vali, classifier.classes_.take(predicted_vali_idx))\n",
    "        map3_values.append(map3)\n",
    "    return np.mean(map3_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_map3_kNN(xlower, xupper, ylower, yupper, cut_threshold=10, \n",
    "                        w_x=500, w_y=1000., w_hour=4., w_weekday=3., w_year=10,\n",
    "                            margin=0., n_neighbors=25, metric='manhattan'\n",
    "                           ):\n",
    "    #print(locals())\n",
    "    \n",
    "    epsilon = 1.0e-5\n",
    "    \n",
    "    if xupper == 10.:\n",
    "        xupper += epsilon\n",
    "    if yupper == 10.:\n",
    "        yupper += epsilon\n",
    "    \n",
    "    train_set_bin_2 = train_set[(train_set.x >= xlower - margin) & (train_set.x < xupper + margin) \n",
    "                              & (train_set.y >= ylower - margin) & (train_set.y < yupper + margin)].copy()\n",
    "    train_set_bin_2.sort_values('time', inplace=True)\n",
    "    Nrows = train_set_bin_2.shape[0]\n",
    "    \n",
    "    eighty_percent_mark = int(0.8*Nrows)\n",
    "    \n",
    "    train_set_bin = train_set_bin_2[:eighty_percent_mark]\n",
    "    \n",
    "    #take the final 20% and shuffle it\n",
    "    validation_set = train_set_bin_2[eighty_percent_mark:]\n",
    "    \n",
    "    N_iter = 5 # this randomly reshuffles the data between the training and testing sets and averages\n",
    "    # reduces overfitting by bayesian optimizer due to choice of train, validation split\n",
    "    \n",
    "    map3_values = []\n",
    "    \n",
    "    for i in range(N_iter):\n",
    "        new_train_set_bin = train_set_bin.copy()\n",
    "        new_validation_set_bin = validation_set.sample(frac=1.) \n",
    "    \n",
    "        # take half the shuffled data, append to train set, and the other half is for \n",
    "        # the validation set.\n",
    "        half_mark = int(new_validation_set_bin.shape[0] * 0.5)\n",
    "        new_train_set_bin.append(new_validation_set_bin[:half_mark])\n",
    "        new_validation_set_bin = new_validation_set_bin[half_mark:]\n",
    "        new_validation_set_bin = new_validation_set_bin[(new_validation_set_bin.x >= xlower) \n",
    "                                                        & (new_validation_set_bin.x < xupper)\n",
    "                                                        & (new_validation_set_bin.y >= ylower)\n",
    "                                                        & (new_validation_set_bin.y < yupper)\n",
    "                                                       ]\n",
    "    \n",
    "        place_counts = new_train_set_bin.place_id.value_counts()\n",
    "        mask = place_counts[new_train_set_bin.place_id.values] >= cut_threshold\n",
    "        new_train_set_bin = new_train_set_bin.loc[mask.values]\n",
    "        \n",
    "        # There is a degree of freedom where all the values can vary simultaneously and maintain\n",
    "        # the same ratio. To counteract this, I do not set w_month. All other distances must\n",
    "        # scale to this one.\n",
    "        \n",
    "        new_train_set_bin.x *= w_x\n",
    "        new_train_set_bin.y *= w_y\n",
    "        new_train_set_bin.hour *= w_hour\n",
    "        new_train_set_bin.weekday *= w_weekday\n",
    "#         new_train_set_bin.month *= w_month\n",
    "        new_train_set_bin.year *= w_year\n",
    "        \n",
    "        new_validation_set_bin.x *= w_x\n",
    "        new_validation_set_bin.y *= w_y\n",
    "        new_validation_set_bin.hour *= w_hour\n",
    "        new_validation_set_bin.weekday *= w_weekday\n",
    "#         new_validation_set_bin.month *= w_month\n",
    "        new_validation_set_bin.year *= w_year\n",
    "\n",
    "        X_train = new_train_set_bin['x y hour weekday month year'.split()].as_matrix()\n",
    "        Y_train = new_train_set_bin['place_id'].values\n",
    "\n",
    "        X_vali = new_validation_set_bin['x y hour weekday month year'.split()].as_matrix()\n",
    "        Y_vali = new_validation_set_bin['place_id'].values\n",
    "\n",
    "        classifier = sklearn.neighbors.KNeighborsClassifier(int(round(n_neighbors)), metric=metric)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        predict_y_vali = classifier.predict_proba(X_vali)\n",
    "        predicted_vali_idx = np.argsort(\n",
    "                predict_y_vali, axis=1)[:, -3:][:, ::-1]\n",
    "        map3 = mapkprecision(Y_vali, classifier.classes_.take(predicted_vali_idx))\n",
    "        map3_values.append(map3)\n",
    "    return np.mean(map3_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_map3_SVC(xlower, xupper, ylower, yupper, cut_threshold=10, \n",
    "                            margin=0., C=1., gamma=0.1\n",
    "                           ):\n",
    "    #print(locals())\n",
    "    \n",
    "    epsilon = 1.0e-5\n",
    "    \n",
    "    if xupper == 10.:\n",
    "        xupper += epsilon\n",
    "    if yupper == 10.:\n",
    "        yupper += epsilon\n",
    "    \n",
    "    train_set_bin_2 = train_set[(train_set.x >= xlower - margin) & (train_set.x < xupper + margin) \n",
    "                              & (train_set.y >= ylower - margin) & (train_set.y < yupper + margin)].copy()\n",
    "    train_set_bin_2.sort_values('time', inplace=True)  \n",
    "    \n",
    "    Nrows = train_set_bin_2.shape[0]\n",
    "    \n",
    "    eighty_percent_mark = int(0.8*Nrows)\n",
    "    \n",
    "    train_set_bin = train_set_bin_2[:eighty_percent_mark]\n",
    "    \n",
    "    #take the final 20% and shuffle it\n",
    "    validation_set = train_set_bin_2[eighty_percent_mark:]\n",
    "    \n",
    "    N_iter = 5 # this randomly reshuffles the data between the training and testing sets and averages\n",
    "    # reduces overfitting by bayesian optimizer due to choice of train, validation split\n",
    "    \n",
    "    map3_values = []\n",
    "    \n",
    "    for i in range(N_iter):\n",
    "        new_train_set_bin = train_set_bin.copy()\n",
    "        new_validation_set_bin = validation_set.sample(frac=1.) \n",
    "    \n",
    "        # take half the shuffled data, append to train set, and the other half is for \n",
    "        # the validation set.\n",
    "        half_mark = int(new_validation_set_bin.shape[0] * 0.5)\n",
    "        new_train_set_bin.append(new_validation_set_bin[:half_mark])\n",
    "        new_validation_set_bin = new_validation_set_bin[half_mark:]\n",
    "        new_validation_set_bin = new_validation_set_bin[(new_validation_set_bin.x >= xlower) \n",
    "                                                        & (new_validation_set_bin.x < xupper)\n",
    "                                                        & (new_validation_set_bin.y >= ylower)\n",
    "                                                        & (new_validation_set_bin.y < yupper)\n",
    "                                                       ]\n",
    "    \n",
    "        place_counts = new_train_set_bin.place_id.value_counts()\n",
    "        mask = place_counts[new_train_set_bin.place_id.values] >= cut_threshold\n",
    "        new_train_set_bin = new_train_set_bin.loc[mask.values]\n",
    "        \n",
    "        # There is a degree of freedom where all the values can vary simultaneously and maintain\n",
    "        # the same ratio. To counteract this, I do not set w_month. All other distances must\n",
    "        # scale to this one.\n",
    "        \n",
    "        new_train_set_bin.x /= 10.\n",
    "        new_train_set_bin.y /= 10.\n",
    "        new_train_set_bin.hour /= 24.\n",
    "        new_train_set_bin.weekday /= 7.\n",
    "        new_train_set_bin.month /= 12.\n",
    "        new_train_set_bin.year /= 2.\n",
    "        \n",
    "        new_validation_set_bin.x /= 10.\n",
    "        new_validation_set_bin.y /= 10.\n",
    "        new_validation_set_bin.hour /= 24.\n",
    "        new_validation_set_bin.weekday /= 7.\n",
    "        new_validation_set_bin.month /= 12.\n",
    "        new_validation_set_bin.year /= 2.\n",
    "\n",
    "        X_train = new_train_set_bin['x y hour weekday month year'.split()].as_matrix()\n",
    "        Y_train = new_train_set_bin['place_id'].values\n",
    "\n",
    "        X_vali = new_validation_set_bin['x y hour weekday month year'.split()].as_matrix()\n",
    "        Y_vali = new_validation_set_bin['place_id'].values\n",
    "\n",
    "        classifier = sklearn.svm.SVC(C=C, kernel='rbf', probability=True, gamma=gamma, \n",
    "                                       decision_function_shape='ovo')\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        predict_y_vali = classifier.predict_proba(X_vali)\n",
    "        predicted_vali_idx = np.argsort(\n",
    "                predict_y_vali, axis=1)[:, -3:][:, ::-1]\n",
    "        map3 = mapkprecision(Y_vali, classifier.classes_.take(predicted_vali_idx))\n",
    "        map3_values.append(map3)\n",
    "    return np.mean(map3_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, Y: 9.2, 5.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a35bff61f18c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;34m\"w_weekday\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w_year\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_neighbors\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \"margin\": (0.005, 0.015, 0.03), \"cut_threshold\": (2, 6, 12)})\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ei\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/bayes_opt/bayesian_optimization.pyc\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m                             \u001b[0mgp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m                             \u001b[0my_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m                             bounds=self.bounds)\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Print stuff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/bayes_opt/bayesian_optimization.pyc\u001b[0m in \u001b[0;36macq_max\u001b[1;34m(ac, gp, y_max, bounds)\u001b[0m\n\u001b[0;32m     46\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# Store it if better than previous minimum(maximum).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 447\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/bayes_opt/bayesian_optimization.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_tries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[0;32m     46\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/bayes_opt/helpers.pyc\u001b[0m in \u001b[0;36mutility\u001b[1;34m(self, x, gp, y_max)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ei'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'poi'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/bayes_opt/helpers.pyc\u001b[0m in \u001b[0;36m_ei\u001b[1;34m(x, gp, y_max, xi)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.pyc\u001b[0m in \u001b[0;36mcdf\u001b[1;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[0mplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# call only if at least 1 entry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m             \u001b[0mgoodargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1673\u001b[0m             \u001b[0mplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shekhar/anaconda2/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.pyc\u001b[0m in \u001b[0;36margsreduce\u001b[1;34m(cond, *args)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0mnewargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0mexpand_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexpand_arr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnewargs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(9) # for the bayes optimizer\n",
    "rs = np.random.RandomState(9) # for bin choices\n",
    "xranges = np.arange(0., 10., 0.1)\n",
    "yranges = np.arange(0., 10., 0.1)\n",
    "\n",
    "for i in range(10):\n",
    "    x = rs.choice(xranges)\n",
    "    y = rs.choice(yranges)\n",
    "    \n",
    "    print(\"X, Y: {}, {}\".format(x, y))\n",
    "    \n",
    "    f = functools.partial(validation_map3_kNN, xlower=x, xupper=x + .1, ylower=y, yupper=y +.1, metric='manhattan')\n",
    "    bo = BayesianOptimization(f=f,\n",
    "                              pbounds={ \"cut_threshold\": (0, 50),\n",
    "                                        \"w_x\": (1, 1000),\n",
    "                                        \"w_y\": (1, 2000),\n",
    "                                        \"w_hour\": (0, 100),\n",
    "                                        \"w_weekday\": (0, 100),\n",
    "                                        \"w_year\": (0, 100),\n",
    "                                        \"n_neighbors\": (3, 100),\n",
    "                                        \"margin\": (0., 0.04)\n",
    "                                      },\n",
    "                              verbose=False)\n",
    "    #w_x=500, w_y=1000., w_hour=4., w_weekday=3., w_year=10,\n",
    "    bo.explore({'w_x': [250, 500, 1000], 'w_y': [500, 1000, 1500], \"w_hour\": (2, 4, 8), \n",
    "                \"w_weekday\": (1, 3, 5), \"w_year\": (5, 10, 20), \"n_neighbors\": (10, 25, 40),\n",
    "                \"margin\": (0.005, 0.015, 0.03), \"cut_threshold\": (2, 6, 12)})\n",
    "    bo.maximize(n_iter=100, acq=\"ei\", xi=0.0)\n",
    "    print(bo.res['max'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(9) # for the bayes optimizer\n",
    "rs = np.random.RandomState(9) # for bin choices\n",
    "xranges = np.arange(0., 10., 0.1)\n",
    "yranges = np.arange(0., 10., 0.1)\n",
    "\n",
    "for i in range(10):\n",
    "    x = rs.choice(xranges)\n",
    "    y = rs.choice(yranges)\n",
    "    \n",
    "    print(\"X, Y: {}, {}\".format(x, y))\n",
    "    \n",
    "    f = functools.partial(validation_map3_kNN, xlower=x, xupper=x + .1, ylower=y, yupper=y +.1, metric='minkowski')\n",
    "    bo = BayesianOptimization(f=f,\n",
    "                              pbounds={ \"cut_threshold\": (0, 50),\n",
    "                                        \"w_x\": (1, 1000),\n",
    "                                        \"w_y\": (1, 2000),\n",
    "                                        \"w_hour\": (0, 100),\n",
    "                                        \"w_weekday\": (0, 100),\n",
    "                                        \"w_year\": (0, 100),\n",
    "                                        \"n_neighbors\": (3, 100),\n",
    "                                        \"margin\": (0., 0.04)\n",
    "                                      },\n",
    "                              verbose=False)\n",
    "    #w_x=500, w_y=1000., w_hour=4., w_weekday=3., w_year=10,\n",
    "    bo.explore({'w_x': [250, 500, 1000], 'w_y': [500, 1000, 1500], \"w_hour\": (2, 4, 8), \n",
    "                \"w_weekday\": (1, 3, 5), \"w_year\": (5, 10, 20), \"n_neighbors\": (10, 25, 40),\n",
    "                \"margin\": (0.005, 0.015, 0.03), \"cut_threshold\": (2, 6, 12)})\n",
    "    bo.maximize(n_iter=100, acq=\"ei\", xi=0.0)\n",
    "    print(bo.res['max'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(9) # for the bayes optimizer\n",
    "rs = np.random.RandomState(9) # for bin choices\n",
    "xranges = np.arange(0., 10., 0.1)\n",
    "yranges = np.arange(0., 10., 0.1)\n",
    "\n",
    "for i in range(10):\n",
    "    x = rs.choice(xranges)\n",
    "    y = rs.choice(yranges)\n",
    "    \n",
    "    print(\"X, Y: {}, {}\".format(x, y))\n",
    "    \n",
    "    f = functools.partial(validation_map3_xgboost, xlower=x, xupper=x + .1, ylower=y, yupper=y +.1)\n",
    "    bo = BayesianOptimization(f=f,\n",
    "                              pbounds={\"n_estimators\": (30, 300), \n",
    "                                       \"learning_rate\": (0.01, 0.5),\n",
    "                                       \"cut_threshold\": (0, 50),\n",
    "                                       \"colsample_bytree\": (0.4, 1.),\n",
    "                                       \"subsample\": (0.5, 1.),\n",
    "                                       \"gamma\": (0.0, 0.3),\n",
    "                                       \"reg_alpha\": (0.0, 2.0),\n",
    "                                       \"reg_lambda\": (0.0, 1.0),\n",
    "                                       \"max_depth\": (3, 10),\n",
    "                                       \"margin\": (0., 0.04)\n",
    "                                      },\n",
    "                              verbose=False)\n",
    "    bo.maximize(init_points=5, n_iter=50, acq=\"ei\", xi=0.0)\n",
    "    print(bo.res['max'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
